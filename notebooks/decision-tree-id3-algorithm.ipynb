{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import time\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from id3 import Id3Estimator\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, \\\n",
    "r2_score, mean_squared_error, mean_absolute_error, median_absolute_error, mean_squared_log_error, explained_variance_score\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREE_DEPTH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_values(y_true, y_pred, target):\n",
    "        \n",
    "    tr = pd.DataFrame(data=y_true, columns=[target])\n",
    "    pr = pd.DataFrame(data=y_pred, columns=[target])\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(15,6))\n",
    "\n",
    "    sns.countplot(x=target, data=tr, ax=ax[0], palette='viridis', alpha=0.7, hue=target, dodge=False)\n",
    "    sns.countplot(x=target, data=pr, ax=ax[1], palette='viridis', alpha=0.7, hue=target, dodge=False)\n",
    "\n",
    "\n",
    "    fig.suptitle('True vs Predicted Comparison', fontsize=20)\n",
    "\n",
    "    ax[0].tick_params(labelsize=12)\n",
    "    ax[1].tick_params(labelsize=12)\n",
    "    ax[0].set_title(\"True values\", fontsize=18)\n",
    "    ax[1].set_title(\"Predicted values\", fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mean = errors / test_labels\n",
    "    mean = mean[np.isfinite(mean)]\n",
    "    mape = 100 * np.mean(mean)\n",
    "    accuracy = 100 - mape\n",
    "\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate run time and prediction accuracy\n",
    "def evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    n_trees = model.get_params()['max_depth']\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # Train and predict 10 times to evaluate time and accuracy\n",
    "    predictions = []\n",
    "    run_times = []\n",
    "    for _ in range(10):\n",
    "        start_time = time.time()\n",
    "        model.fit(x_train, y_train)\n",
    "        predictions.append(model.predict(x_test))\n",
    "    \n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "    \n",
    "    # Run time and predictions need to be averaged\n",
    "    run_time = np.mean(run_times)\n",
    "    predictions = np.mean(np.array(predictions), axis = 0)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    errors = abs(predictions - y_test)\n",
    "    mean_error = np.mean(errors)\n",
    "    mean = errors / y_test\n",
    "    mean = mean[np.isfinite(mean)]\n",
    "    mape = 100 * np.mean(mean)\n",
    "    accuracy = 100 - mape\n",
    "    \n",
    "    # Return results in a dictionary\n",
    "    results = {'time': run_time, 'error': mean_error, 'accuracy': accuracy, 'depth': n_trees, 'n_features': n_features}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, param = 'max_depth', name = 'Depth'):\n",
    "    param_name = 'param_%s' % param\n",
    "\n",
    "    # Extract information from the cross validation model\n",
    "    train_scores = model.cv_results_['mean_train_score']\n",
    "    test_scores = model.cv_results_['mean_test_score']\n",
    "    train_time = model.cv_results_['mean_fit_time']\n",
    "    param_values = list(model.cv_results_[param_name])\n",
    "    \n",
    "    # Plot the scores over the parameter\n",
    "    plt.subplots(1, 2, figsize=(10, 6))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(param_values, train_scores, 'bo-', label = 'train')\n",
    "    plt.plot(param_values, test_scores, 'go-', label = 'test')\n",
    "    plt.ylim(ymin = -10, ymax = 0)\n",
    "    plt.legend()\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Neg Mean Absolute Error')\n",
    "    plt.title('Score vs %s' % name)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(param_values, train_time, 'ro-')\n",
    "    plt.ylim(ymin = 0.0, ymax = 2.0)\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Train Time (sec)')\n",
    "    plt.title('Training Time vs %s' % name)\n",
    "    \n",
    "    \n",
    "    plt.tight_layout(pad = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read\n",
    "df = pd.read_csv(\"spotify-dataset.csv\")\n",
    "\n",
    "# lower the attribute\n",
    "df['Top Genre'] = (df[\"Top Genre\"].str.strip()).str.lower()\n",
    "\n",
    "# drop genres that have less than 20 instances\n",
    "to_remove = [genre for genre in df['Top Genre'].unique() if df['Top Genre'].value_counts()[genre] < 20] \n",
    "for r in to_remove:\n",
    "    df = df[df['Top Genre'] != r]\n",
    "\n",
    "# convert negative values to positive, because the percenption of sound is relative (-N dB == N dB in human ear)\n",
    "df['Loudness (dB)'] = df['Loudness (dB)'].abs()\n",
    "\n",
    "# convert duration to int\n",
    "df['Length (Duration)'] = pd.to_numeric(df['Length (Duration)'].str.replace(',',''))\n",
    "\n",
    "# drop not used columns\n",
    "df.drop(columns = ['Index', 'Title', 'Artist', 'Year'], inplace=True)\n",
    "\n",
    "# encode genres\n",
    "genres = list(df['Top Genre'].unique())\n",
    "df['Top Genre Encoded'] = df['Top Genre'].apply(lambda x: genres.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'adult standards',\n",
       " 1: 'album rock',\n",
       " 2: 'alternative metal',\n",
       " 3: 'classic rock',\n",
       " 4: 'pop',\n",
       " 5: 'modern rock',\n",
       " 6: 'alternative rock',\n",
       " 7: 'dutch indie',\n",
       " 8: 'dutch cabaret',\n",
       " 9: 'permanent wave',\n",
       " 10: 'classic uk pop',\n",
       " 11: 'dance pop',\n",
       " 12: 'dutch pop',\n",
       " 13: 'british soul',\n",
       " 14: 'irish rock',\n",
       " 15: 'art rock',\n",
       " 16: 'british invasion',\n",
       " 17: 'dance rock',\n",
       " 18: 'glam rock',\n",
       " 19: 'europop'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_genres= {}\n",
    "for i, genre in enumerate(genres):\n",
    "    dict_genres[i] = genre\n",
    "    \n",
    "dict_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top Genre</th>\n",
       "      <th>Beats Per Minute (BPM)</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Loudness (dB)</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Length (Duration)</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Top Genre Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>157</td>\n",
       "      <td>30</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>68</td>\n",
       "      <td>201</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>album rock</td>\n",
       "      <td>135</td>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>81</td>\n",
       "      <td>207</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>alternative metal</td>\n",
       "      <td>173</td>\n",
       "      <td>96</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>classic rock</td>\n",
       "      <td>106</td>\n",
       "      <td>82</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>87</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>pop</td>\n",
       "      <td>102</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>54</td>\n",
       "      <td>257</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1987</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>119</td>\n",
       "      <td>24</td>\n",
       "      <td>75</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>216</td>\n",
       "      <td>83</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1988</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>168</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>298</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1989</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>94</td>\n",
       "      <td>21</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>128</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>175</td>\n",
       "      <td>76</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "      <td>95</td>\n",
       "      <td>136</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1993</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>133</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>83</td>\n",
       "      <td>148</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1465 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Top Genre  Beats Per Minute (BPM)  Energy  Danceability  \\\n",
       "0       adult standards                     157      30            53   \n",
       "1            album rock                     135      79            50   \n",
       "3     alternative metal                     173      96            43   \n",
       "4          classic rock                     106      82            58   \n",
       "6                   pop                     102      71            71   \n",
       "...                 ...                     ...     ...           ...   \n",
       "1987    adult standards                     119      24            75   \n",
       "1988    adult standards                     168       7            17   \n",
       "1989    adult standards                      94      21            70   \n",
       "1990    adult standards                     175      76            36   \n",
       "1993    adult standards                     133      50            49   \n",
       "\n",
       "      Loudness (dB)  Liveness  Valence  Length (Duration)  Acousticness  \\\n",
       "0                14        11       68                201            94   \n",
       "1                11        17       81                207            17   \n",
       "3                 4         3       37                269             0   \n",
       "4                 5        10       87                256             1   \n",
       "6                 6        13       54                257             6   \n",
       "...             ...       ...      ...                ...           ...   \n",
       "1987             15         9       43                216            83   \n",
       "1988             21        14       10                298            92   \n",
       "1989             12        11       72                128            84   \n",
       "1990              8        76       95                136            73   \n",
       "1993             10        16       83                148            74   \n",
       "\n",
       "      Speechiness  Popularity  Top Genre Encoded  \n",
       "0               3          71                  0  \n",
       "1               7          39                  1  \n",
       "3               4          76                  2  \n",
       "4               3          59                  3  \n",
       "6               3          74                  4  \n",
       "...           ...         ...                ...  \n",
       "1987           12          68                  0  \n",
       "1988            3          66                  0  \n",
       "1989            7          63                  0  \n",
       "1990            6          69                  0  \n",
       "1993            3          56                  0  \n",
       "\n",
       "[1465 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform analysis\n",
    "\n",
    "The analisis performed, conssits in a classification with random forest, that ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['Top Genre Encoded']\n",
    "features = ['Beats Per Minute (BPM)', 'Energy', 'Danceability', 'Loudness (dB)', 'Liveness', 'Valence', 'Length (Duration)', 'Acousticness', 'Speechiness', 'Popularity']\n",
    "X = df[features]\n",
    "Y = df[targets]\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, Y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = RandomForestClassifier(max_depth = TREE_DEPTH , random_state=1, n_estimators=10)\n",
    "#model.fit(train_X, train_y)\n",
    "\n",
    "# 1. Instantiate\n",
    "# default criterion=gini\n",
    "# you can swap to criterion=entropy for ID3 implementation (maximizing information gain)\n",
    "model = DecisionTreeClassifier(criterion=\"entropy\", max_depth = TREE_DEPTH,random_state=1)\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 2,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': 1,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  1,  1,  1, 12,  1,  1,  1,  1,  1,  1,  1,  1, 12,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1, 12,  1,  1,  1,  1,  1,  1,  1, 12,  1, 12,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, 12,  1,  1,  1,  1, 12,  1,  1,  1,\n",
       "        1,  1, 12,  1,  1,  1,  1,  1,  1,  1,  1,  1, 12, 12,  1, 12,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 12,\n",
       "        1,  1,  1,  1, 12,  1,  1,  1,  1, 12,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, 12,  1,  1, 12,  1,  1,  1,  1, 12,  1,  1,  1,  1, 12,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, 12,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 12,  1,\n",
       "        1,  1,  1,  1, 12,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 12,\n",
       "        1,  1,  1, 12,  1, 12,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1, 12,  1,  1,  1,  1, 12, 12,  1,\n",
       "        1,  1,  1,  1, 12,  1, 12,  1,  1,  1,  1,  1,  1,  1, 12,  1,  1,\n",
       "        1,  1,  1,  1, 12,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1, 12,  1,  1,  1,  1,  1,  1, 12,  1,  1,  1, 12,  1,\n",
       "        1,  1,  1,  1,  1,  1, 12,  1, 12,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1, 12,  1,  1,  1,  1, 12,  1, 12, 12,  1,\n",
       "        1, 12,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "splitter = ['best', 'random']\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2,4,6,8,10,12]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'splitter': splitter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 277 out of 300 | elapsed:    2.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='entropy',\n",
       "                                                    max_depth=2,\n",
       "                                                    max_features=None,\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    presort='deprecated',\n",
       "                                                    random_state=1,\n",
       "                                                    splitter='best'),\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [2, 4, 6, 8, 10, 12, None],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'splitter': ['best', 'random']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = DecisionTreeClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'splitter': 'random',\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 6}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best params\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model with best params\n",
    "best_model = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_y['Top Genre Encoded'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 5.3542 degrees.\n",
      "Accuracy = 18.90%.\n"
     ]
    }
   ],
   "source": [
    "base_accuracy = evaluate(model, test_X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 5.4741 degrees.\n",
      "Accuracy = 34.48%.\n"
     ]
    }
   ],
   "source": [
    "random_accuracy = evaluate(best_model, test_X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-22-c9b59d9414e5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-c9b59d9414e5>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print('Improvement of {:0.2f}%.'.format((random_accuracy - base_accuracy))\u001b[0m\n\u001b[1;37m                                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format((random_accuracy - base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'splitter': ['random'],\n",
    "    'max_depth': [3, 5, 9, 12],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12]\n",
    "}\n",
    "\n",
    "# This will try out \n",
    "# 1 (bootstrap) * 4 (max_depth) * 2 (max_features) * 3 (min_smaples_leaf) \n",
    "# * 3 (min_samples_split) * 4 (n_estimators) = 288 combinations of settings.\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best grid\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, test_X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format(grid_accuracy - base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = evaluate_model(model, train_X, train_y, test_X, labels)\n",
    "model_results['model'] = 'base_model'\n",
    "model_results['model'] = 'best_model_gs_model'\n",
    "#model_results['accuracy'] = base_accuracy\n",
    "best_model_results = evaluate_model(best_model, train_X, train_y, test_X, labels)\n",
    "best_model_results['model'] = 'best_model_rf_model'\n",
    "best_model_results['accuracy'] = random_accuracy\n",
    "best_grid_results = evaluate_model(best_grid, train_X, train_y, test_X, labels)\n",
    "best_grid_results['model'] = 'best_model_gs_model'\n",
    "best_grid_results['accuracy'] = grid_accuracy\n",
    "#best_grid_results['model'] = 'base_model'\n",
    "\n",
    "#tmp = best_grid_results['error']\n",
    "#best_grid_results['error'] = model_results['error']\n",
    "#model_results['error'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = {'model': [],\n",
    "              'accuracy': [],\n",
    "              'error': [],\n",
    "              'n_features': [],\n",
    "              'depth': [],\n",
    "              'time': []}\n",
    "                        \n",
    "#for m in [model_results, best_model_results, best_grid_results]:\n",
    "for m in [model_results, best_model_results, best_grid_results]:\n",
    "    comparison['accuracy'].append(round(m['accuracy'], 3))\n",
    "    comparison['error'].append(round(m['error'], 3))\n",
    "    comparison['model'].append(m['model'])\n",
    "    comparison['n_features'].append(m['n_features'])\n",
    "    comparison['depth'].append(int(m['depth']))\n",
    "    comparison['time'].append(round(m['time'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame.from_dict(comparison, orient = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison[['model', 'accuracy', 'error', 'n_features', 'depth', 'time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize labels in test data versus predictions and number of \n",
    "# equivalente values\n",
    "compare_values(labels, validation_predictions, 'Top Genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representation of value frequency\n",
    "df.plot.hist(subplots=True, layout=(6,2), figsize=(10, 10), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values of Popularity for each genre\n",
    "df.groupby(\"Top Genre\").Popularity.mean().sort_values(ascending=False)[:5].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of Popularity - Danceability\n",
    "g = sns.scatterplot(x='Popularity', y='Danceability', hue='Top Genre', data=df, legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "sns.heatmap(df.drop(['Top Genre'], axis=1).corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "best_grid_predictions = best_grid.predict(test_X)\n",
    "mat = confusion_matrix(labels, best_grid_predictions)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=genres, yticklabels=genres)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faceting is the act of breaking data variables up across multiple subplots \n",
    "# and combining those subplots into a single figure.\n",
    "# In this case it will be the points of P1 per floor\n",
    "g = sns.FacetGrid(df, col='Top Genre', col_wrap=5)\n",
    "g = g.map(sns.kdeplot, 'Popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse matrix\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "scatter_matrix(df.drop(['Top Genre'], axis=1), alpha=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalues = list(range(len(comparison)))\n",
    "plt.subplots(1, 2, figsize=(10, 6))\n",
    "plt.subplot(121)\n",
    "plt.bar(xvalues, comparison['accuracy'], color = 'g', edgecolor = 'k', linewidth = 1.8)\n",
    "plt.xticks(xvalues, comparison['model'], rotation = 45, fontsize = 12)\n",
    "plt.ylim(ymin = 91, ymax = 94)\n",
    "plt.xlabel('model'); plt.ylabel('Accuracy (%)'); plt.title('Accuracy Comparison');\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.bar(xvalues, comparison['error'], color = 'r', edgecolor = 'k', linewidth = 1.8)\n",
    "plt.xticks(xvalues, comparison['model'], rotation = 45)\n",
    "plt.ylim(ymin = 3.5, ymax = 6)\n",
    "plt.xlabel('model'); plt.ylabel('Error (deg)'); plt.title('Error Comparison');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can perform grid search over only one parameter to observe the effects of changing that parameter on performance. \n",
    "# We will look at training time, training set accuracy, and testing set accuracy.\n",
    "# Grid with only the number of trees changed\n",
    "tree_grid = {'max_depth': [int(x) for x in np.linspace(1, 301, 30)]}\n",
    "\n",
    "# Create the grid search model and fit to the training data\n",
    "tree_grid_search = GridSearchCV(best_grid, param_grid=tree_grid, verbose = 2, n_jobs=-1, cv = 3,\n",
    "                                scoring = 'neg_mean_absolute_error', return_train_score=True)\n",
    "tree_grid_search.fit(train_X, train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(tree_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of Samples required in each leaf node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_grid = {'min_samples_leaf': list(range(1, train_X.shape[1] + 1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid search and fit on the training data\n",
    "feature_grid_search = GridSearchCV(best_grid, param_grid=feature_grid, cv = 3, n_jobs=-1, verbose= 2,\n",
    "                                  scoring = 'neg_mean_absolute_error', return_train_score=True)\n",
    "feature_grid_search.fit(train_X, train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(feature_grid_search, param='min_samples_leaf', name = 'Number of Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of Features at Each Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_grid = {'max_features': list(range(1, train_X.shape[1] + 1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid search and fit on the training data\n",
    "feature_grid_search = GridSearchCV(best_grid, param_grid=feature_grid, cv = 3, n_jobs=-1, verbose= 2,\n",
    "                                  scoring = 'neg_mean_absolute_error', return_train_score=True)\n",
    "feature_grid_search.fit(train_X, train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(feature_grid_search, param='max_features', name = 'Max Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot model statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(test_y, validation_predictions)\n",
    "mse = mean_squared_error(test_y, validation_predictions) \n",
    "mean_absolute_error = mean_absolute_error(test_y, validation_predictions) \n",
    "explained_variance = explained_variance_score(test_y, validation_predictions)\n",
    "median_absolute_error = median_absolute_error(test_y, validation_predictions)\n",
    "mean_squared_log_error = mean_squared_log_error(test_y, validation_predictions)\n",
    "\n",
    "print('r2:',{round(r2,4)})\n",
    "print('MSE:',{round(mse,4)})\n",
    "print('RMSE:',{round(np.sqrt(mse),4)})\n",
    "print('MAE:',{round(mean_absolute_error,4)})\n",
    "print('explained_variance:',{round(explained_variance,4)})    \n",
    "print('mean_squared_log_error:',{round(mean_squared_log_error,4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score_ = cross_val_score(model, train_X, train_y, cv = 10, scoring = 'accuracy')\n",
    "print('cross validation mean ',{cross_val_score_.mean()})\n",
    "print('cross validation std ',{cross_val_score_.std()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_randforest = cross_val_predict(model, train_X, train_y, cv = 10)\n",
    "recall_score_ = recall_score(train_y, y_randforest, average = \"micro\")\n",
    "precission_score_ = precision_score(train_y, y_randforest, average = \"micro\")\n",
    "f1_score = 2 * (precission_score_ * recall_score_) / (precission_score_ + recall_score_)\n",
    "print('Recall Score:',{recall_score_})\n",
    "print('Precision Score:',{precission_score_})\n",
    "print('F1 Score:', {f1_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = list(df[features].columns.values)\n",
    "class_names = list(df['Top Genre'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as dot file\n",
    "export_graphviz(best_grid, out_file='tree_depth_best_grid.dot', \n",
    "                feature_names = column_names,\n",
    "                class_names = class_names,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to png using system command (requires Graphviz)\n",
    "# python -m pip install graphviz\n",
    "# python -m pip install pydot\n",
    "(graph,) = pydot.graph_from_dot_file('tree_depth_best_grid.dot')\n",
    "graph.write_png('tree_depth_best_grid.png')\n",
    "\n",
    "# Display in jupyter notebook\n",
    "Image(filename = 'tree_depth_best_grid.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
